{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Data collection\n",
    "    - web scraping \n",
    "    - Data cleaning\n",
    "    (élinime les doublons, et les balise HTML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://ironlionsion.com/en/?_route=homepage\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "#print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = [p.text for p in soup.find_all('p')]\n",
    "\n",
    "#print(paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenatio de tous les pargraphs\n",
    "\n",
    "knowledge_base = \"\\n\".join(paragraphs)\n",
    "#print(knowledge_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nettoyage pour le chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#suppression des espaces excessifs et des lignes vide\n",
    "cleaned_text = \"\\n\".join([line.strip() for line in knowledge_base.split(\"\\n\") if line.strip() != \"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose your style\n",
      "Choose your style\n",
      "Follow the movement\n",
      "of the price is directly donated to two essential causes for each t-shirt sold\n",
      "We contribute to the reforestation of areas burned and devastated by bombings in the north of the country\n",
      "We provide crucial assistance to injured soldiers, both physically and psychologically, to honor their courage and commitment to the nation.\n",
      "Join the movement\n",
      "Join the movement\n",
      "Join the movement\n",
      "Join the movement\n",
      "Join the movement\n",
      "Join the movement\n",
      "Join the movement\n",
      "Join the movement\n",
      "Join the movement\n",
      "Join the movement\n",
      "By purchasing this T-shirt, you support our cause and become an ambassador of solidarity and hope. You will help restore our forests and support our brave soldiers.\n",
      "Act now!\n",
      "Act now!\n",
      "Act now!\n",
      "Act now!\n",
      "Act now!\n",
      "Don't miss this opportunity to take part in this noble cause. Order your 'Iron Like a Lion in Zion' t-shirt today and join us in our mission of reconstruction and support.\n",
      "Together, we are stronger. Together, we are like a lion in Zion.\n",
      "Follow the movement\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Choose your style',\n",
       " 'Choose your style',\n",
       " 'Follow the movement',\n",
       " 'of the price is directly donated to two essential causes for each t-shirt sold',\n",
       " 'We contribute to the reforestation of areas burned and devastated by bombings in the north of the country',\n",
       " 'We provide crucial assistance to injured soldiers, both physically and psychologically, to honor their courage and commitment to the nation.',\n",
       " 'Join the movement',\n",
       " 'Join the movement',\n",
       " 'Join the movement',\n",
       " 'Join the movement',\n",
       " 'Join the movement',\n",
       " 'Join the movement',\n",
       " 'Join the movement',\n",
       " 'Join the movement',\n",
       " 'Join the movement',\n",
       " 'Join the movement',\n",
       " 'By purchasing this T-shirt, you support our cause and become an ambassador of solidarity and hope. You will help restore our forests and support our brave soldiers.',\n",
       " 'Act now!',\n",
       " 'Act now!',\n",
       " 'Act now!',\n",
       " 'Act now!',\n",
       " 'Act now!',\n",
       " \"Don't miss this opportunity to take part in this noble cause. Order your 'Iron Like a Lion in Zion' t-shirt today and join us in our mission of reconstruction and support.\",\n",
       " 'Together, we are stronger. Together, we are like a lion in Zion.',\n",
       " 'Follow the movement']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#éliminations des doublons\n",
    "# on divise le text en ligne\n",
    "lines =  cleaned_text.split('\\n')\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'act now!',\n",
       " 'by purchasing this t-shirt, you support our cause and become an ambassador of solidarity and hope. you will help restore our forests and support our brave soldiers.',\n",
       " 'choose your style',\n",
       " \"don't miss this opportunity to take part in this noble cause. order your 'iron like a lion in zion' t-shirt today and join us in our mission of reconstruction and support.\",\n",
       " 'follow the movement',\n",
       " 'join the movement',\n",
       " 'of the price is directly donated to two essential causes for each t-shirt sold',\n",
       " 'together, we are stronger. together, we are like a lion in zion.',\n",
       " 'we contribute to the reforestation of areas burned and devastated by bombings in the north of the country',\n",
       " 'we provide crucial assistance to injured soldiers, both physically and psychologically, to honor their courage and commitment to the nation.'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_lines = set(line.strip().lower() for line in lines if line.strip() != \"\")\n",
    "unique_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"by purchasing this t-shirt, you support our cause and become an ambassador of solidarity and hope. you will help restore our forests and support our brave soldiers.\\nof the price is directly donated to two essential causes for each t-shirt sold\\ntogether, we are stronger. together, we are like a lion in zion.\\nwe provide crucial assistance to injured soldiers, both physically and psychologically, to honor their courage and commitment to the nation.\\nact now!\\ndon't miss this opportunity to take part in this noble cause. order your 'iron like a lion in zion' t-shirt today and join us in our mission of reconstruction and support.\\nchoose your style\\nfollow the movement\\nwe contribute to the reforestation of areas burned and devastated by bombings in the north of the country\\njoin the movement\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deduplicated_text = \"\\n\".join(unique_lines)\n",
    "deduplicated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['act now!',\n",
       " 'by purchasing this t-shirt, you support our cause and become an ambassador of solidarity and hope. you will help restore our forests and support our brave soldiers.',\n",
       " 'choose your style',\n",
       " \"don't miss this opportunity to take part in this noble cause. order your 'iron like a lion in zion' t-shirt today and join us in our mission of reconstruction and support.\",\n",
       " 'follow the movement',\n",
       " 'join the movement',\n",
       " 'of the price is directly donated to two essential causes for each t-shirt sold',\n",
       " 'together, we are stronger. together, we are like a lion in zion.',\n",
       " 'we contribute to the reforestation of areas burned and devastated by bombings in the north of the country',\n",
       " 'we provide crucial assistance to injured soldiers, both physically and psychologically, to honor their courage and commitment to the nation.']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tris des lignes\n",
    "unique_lines_sorted = sorted(unique_lines)\n",
    "unique_lines_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va utiliser unmodèle LLM GPT-2 qui est un modèle open source\n",
    "\n",
    "Avec hugging face transformers, on peut acceder facuilement à GPT-2 et on va le faire avec pyTorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chargement du model GPT-2\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "#charge le tokenizer et le modèle GPT-2\n",
    "tokenizer =  GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "#generate text with gpt2\n",
    "print(tokenizer.pad_token_id) # ici c'est none\n",
    "\n",
    "# Définir manuellement le token de padding\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def generate_response(prompt):\n",
    "    inputs = tokenizer.encode(prompt, return_tensors = 'pt') # it prepare the model's entry\n",
    "    outputs = model.generate(\n",
    "        inputs, \n",
    "        max_length=150, \n",
    "        num_return_sequences = 1, \n",
    "        temperature = 0.7,\n",
    "        do_sample = True, # active l'echantillonnage\n",
    "        pad_token_id = tokenizer.eos_token_id, #définit le token de padding 50256\n",
    "        attention_mask = inputs.ne(tokenizer.pad_token_id) # ajoute une attention explicite\n",
    "    )\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is LLM in machine learning ?)\n",
      "\n",
      "Machine learning is a process where data is generated about a data set of its properties or attributes which are then used to predict or predict future events.\n",
      "\n",
      "In general, machine learning is generally a linear process based on the structure of data.\n",
      "\n",
      "In a previous post I outlined that machine learning in general can be used to learn which properties or attributes of data are expected and will be used in future research. However, it should also be noted that machine learning is not a linear process.\n",
      "\n",
      "The basic idea behind machine learning is that the computer is capable of performing a computation on data in order to find out what properties are expected and will be used in future research.\n",
      "\n",
      "In this\n"
     ]
    }
   ],
   "source": [
    "# it is an example \n",
    "\n",
    "prompt = \"what is LLM in machine learning ?\"\n",
    "response = generate_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine tuning the model\n",
    "enfin :-) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encodage\n",
    "encodings =  tokenizer(\"\\n\\n\".join(deduplicated_text), return_tensors = 'pt', max_length = 1024, truncation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate>=0.26.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configuration of the  training args\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "trainings_args = TrainingArguments(\n",
    "   output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    logging_dir=\"./logs\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset for training\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "# Add the labels (same as input_ids for language modeling tasks)\n",
    "encodings['labels'] = encodings['input_ids'].clone()\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d595254f79b4690bea8413de2a0d5b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fandr\\AppData\\Local\\Temp\\ipykernel_14208\\1768826201.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 54.8972, 'train_samples_per_second': 0.055, 'train_steps_per_second': 0.055, 'train_loss': 1.5705798467000325, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3, training_loss=1.5705798467000325, metrics={'train_runtime': 54.8972, 'train_samples_per_second': 0.055, 'train_steps_per_second': 0.055, 'total_flos': 1567752192000.0, 'train_loss': 1.5705798467000325, 'epoch': 3.0})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entraîner le modèle\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=trainings_args,\n",
    "    train_dataset=train_dataset\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_texts = [\n",
    "    \"be the change! by purchasing this cap, you help rebuild our homes and support displaced families.\",\n",
    "    \"wear your values. get this hoodie and join a movement of compassion and action.\",\n",
    "    \"this is your chance to make a difference. order now and stand with us in unity.\",\n",
    "    \"a portion of your purchase goes directly to funding scholarships for children affected by the war.\",\n",
    "    \"let's heal together. join the 'rebuild and rise' movement today.\",\n",
    "    \"for every product sold, we donate to initiatives supporting mental health for veterans.\",\n",
    "    \"every small action counts. get your t-shirt and take a stand for the planet and our people.\",\n",
    "    \"by supporting this campaign, you contribute to the restoration of wildlife habitats destroyed by conflict.\",\n",
    "    \"stand proud, wear hope. your purchase empowers soldiers and helps them rebuild their lives.\",\n",
    "    \"act today, and be part of a brighter tomorrow. together, we rise stronger.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fandr\\AppData\\Local\\Temp\\ipykernel_14208\\1768826201.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcb16ff14bd24ee58e8a06a44b5eb7e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultats de l'évaluation  {'eval_loss': 5.208493232727051, 'eval_runtime': 1.2946, 'eval_samples_per_second': 7.724, 'eval_steps_per_second': 1.545, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "validation_encodings =  tokenizer(validation_texts, return_tensors='pt', max_length=1024, truncation=True, padding=True)\n",
    "validation_encodings['labels'] = validation_encodings['input_ids'].clone()\n",
    "\n",
    "#create vthe dataset\n",
    "\n",
    "validation_dataset = CustomDataset(validation_encodings)\n",
    "\n",
    "#evaluation\n",
    "\n",
    "eval_results = trainer.evaluate(eval_dataset=validation_dataset)\n",
    "print(\"Résultats de l'évaluation \", eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va tester ce modèle avec des texts qui sont pas dans le dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt : Support our cause and make a difference today.\n",
      "Generated text : Support our cause and make a difference today. For more information, visit our website: www.petitionsforlove.org\n",
      "--------------------------------------------------\n",
      "Prompt : Reforest burned areas with your help.\n",
      "Generated text : Reforest burned areas with your help.\n",
      "\n",
      "3) In the event you have an unlimited supply of food, fuel and ammunition, you must take care to find places in the area you plan on harvesting your crops.\n",
      "\n",
      "4) If you\n",
      "--------------------------------------------------\n",
      "Prompt : Together, we stand as strong as a lion.\n",
      "Generated text : Together, we stand as strong as a lion.\n",
      "\n",
      "\"What's going on with my family — I know who they are,\" she said. \"And what's going on in their lives, just to be the best you can be.\"\n",
      "\n",
      "--------------------------------------------------\n",
      "Prompt : Assist injured soldiers through solidarity.\n",
      "Generated text : Assist injured soldiers through solidarity.\n",
      "\n",
      "A military officer was shot dead by suspected militants who said he was carrying a Tavor rifle.\n",
      "\n",
      "An Iraqi soldier was shot by a suspected Islamic State militant in the village of Moklama.\n",
      "--------------------------------------------------\n",
      "Prompt : C'est quoi l'objectif de ce site en français ?\n",
      "Generated text : C'est quoi l'objectif de ce site en français ? dans leur à s'abstainte là qui rien que ces être de vue à sa site d'un m\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "#load the model fine-tuned by using pipeline\n",
    "\n",
    "text_generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "#notre prompt de test\n",
    "\n",
    "test_prompts = [\n",
    "    \"Support our cause and make a difference today.\",\n",
    "    \"Reforest burned areas with your help.\",\n",
    "    \"Together, we stand as strong as a lion.\",\n",
    "    \"Assist injured soldiers through solidarity.\",\n",
    "    \"C'est quoi l'objectif de ce site en français ?\"\n",
    "]\n",
    "\n",
    "#generate response\n",
    "\n",
    "for prompt in test_prompts:\n",
    "    generated_text = text_generator(prompt, max_length = 50, num_return_sequences = 1)\n",
    "    print(f\"Prompt : {prompt}\")\n",
    "    print(f\"Generated text : {generated_text[0]['generated_text']}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quastion & Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0907a430fb074be79c0a78281db2bb7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fandr\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\fandr\\.cache\\huggingface\\hub\\models--t5-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48b2cb23ad674d9ca9e729a1788b2510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe6a4d1f5bed465586950e9d7c2680b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05cae5dadb3b4667968120bb1bdd88ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3bba3b115874872a402195006c01cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "question_generator = pipeline(\"text2text-generation\", model=\"t5-base\")\n",
    "\n",
    "def generate_question_answer(text):\n",
    "\n",
    "    #generate question from the text\n",
    "    question = question_generator(f\"generate question: {text}\")\n",
    "    \n",
    "    #here we can add an answer\n",
    "    answer = text\n",
    "\n",
    "    return question[0]['generated_text'], answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: False\n",
      "Answer: L'organisation soutient les soldats blessés et contribue à la reforestation des zones dévastées.\n"
     ]
    }
   ],
   "source": [
    "#eg\n",
    "text = \"L'organisation soutient les soldats blessés et contribue à la reforestation des zones dévastées.\"\n",
    "question, answer = generate_question_answer(text)\n",
    "print(\"Question:\", question)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
